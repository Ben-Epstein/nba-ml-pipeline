{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "27e6faed",
   "metadata": {},
   "source": [
    "![ZenML](_assets/Logo/zenml.svg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8585ad8e",
   "metadata": {},
   "source": [
    "https://github.com/zenml-io/nba-ml-pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c4de5a07",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8eaaa90",
   "metadata": {},
   "source": [
    "# Why ZenML"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39c901ce",
   "metadata": {},
   "source": [
    "![Sam](_assets/sam.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e74ddf61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mInitializing ZenML repository at /home/hamza/temp_stuff/zenml_demo/nba-ml-pipeline.\u001b[0m\n",
      "/home/hamza/.virtualenvs/zenml_dev/lib/python3.8/site-packages/pandas/compat/__init__.py:120: UserWarning: Could not import the lzma module. Your installed Python is incomplete. Attempting to use lzma compression will result in a RuntimeError.\n",
      "  warnings.warn(msg)\n",
      "\u001b[1;35mRegistered stack component with name 'local_orchestrator'.\u001b[0m\n",
      "\u001b[1;35mRegistered stack component with name 'local_metadata_store'.\u001b[0m\n",
      "\u001b[1;35mRegistered stack component with name 'local_artifact_store'.\u001b[0m\n",
      "\u001b[1;35mRegistered stack with name 'local_stack'.\u001b[0m\n",
      "\u001b[32mZenML repository initialized at /home/hamza/temp_stuff/zenml_demo/nba-ml-pipeline.\u001b[0m\n",
      "\u001b[32mActive stack: local_stack\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!zenml init\n",
    "!zenml stack set local_stack"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a16c02d0",
   "metadata": {},
   "source": [
    "# Chapter 1 - Exploring NBA Data\n",
    "## Did Steph Curry Change the Game?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "531ddbed",
   "metadata": {},
   "source": [
    "https://www.youtube.com/watch?v=GEMVGHoenXM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e4108c6",
   "metadata": {},
   "source": [
    "![Steph Curry Drains the Game Winner vs Oklahoma City](https://i.makeagif.com/media/3-20-2016/7N5RWB.gif)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f52add8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We'll use this date in our pipelines\n",
    "CURRYS_THREE_POINTER = '2016-02-27'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e09e2f66",
   "metadata": {},
   "source": [
    "![PipelineStructure](_assets/DriftDetectionPipeline.png \"PipelineStructure\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27700042",
   "metadata": {},
   "source": [
    "## Creating our first step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f57f2a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reference\n",
    "from zenml.steps import step\n",
    "from steps.importer import ImporterConfig\n",
    "import pandas as pd\n",
    "\n",
    "@step\n",
    "def game_data_importer(config: ImporterConfig) -> pd.DataFrame:\n",
    "    \"\"\"Downloads season data from NBA API and returns a pd.DataFrame\"\"\"\n",
    "    dataframes = []\n",
    "    for season in config.seasons:\n",
    "        print(f\"Fetching data for season: {season}\")\n",
    "        dataframes.append(leaguegamelog.LeagueGameLog(season=season, timeout=180).get_data_frames()[0])\n",
    "        # sleep so as not to bomb api server :-)\n",
    "        time.sleep(2)\n",
    "    return pd.concat(dataframes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce8e0cb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Import our steps\n",
    "from steps.importer import game_data_importer\n",
    "from steps.splitter import date_based_splitter, SplitConfig"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1627c7c5",
   "metadata": {},
   "source": [
    "## Creating an exploratory pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1225c6eb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from zenml.pipelines import pipeline\n",
    "\n",
    "@pipeline\n",
    "def data_analysis_pipeline(\n",
    "        importer,          # Import NBA game data\n",
    "        drift_splitter,    # Split data at relevant date\n",
    "        drift_detector,    # Compare data distributions\n",
    "):\n",
    "    \"\"\"Links all the steps together in a pipeline\"\"\"\n",
    "    raw_data = importer()\n",
    "    reference_dataset, comparison_dataset = drift_splitter(raw_data)\n",
    "    drift_report, _ = drift_detector(reference_dataset, comparison_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34b92917",
   "metadata": {},
   "source": [
    "https://blog.zenml.io/zenml-loves-evidently/  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01338745",
   "metadata": {},
   "source": [
    "![Evidently](_assets/zenml+evidently.png \"Evidently\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aaa3006",
   "metadata": {},
   "outputs": [],
   "source": [
    "!zenml integration install evidently"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "734be408",
   "metadata": {},
   "outputs": [],
   "source": [
    "from zenml.integrations.evidently.steps import (\n",
    "    EvidentlyProfileConfig,\n",
    "    EvidentlyProfileStep,\n",
    ")\n",
    "\n",
    "evidently_drift_detector = EvidentlyProfileStep(\n",
    "    EvidentlyProfileConfig(\n",
    "        column_mapping=None,\n",
    "        profile_sections=[\"datadrift\"],\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42cdb618",
   "metadata": {},
   "source": [
    "### Run the pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d019fff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the pipeline\n",
    "eda_pipeline = data_analysis_pipeline(\n",
    "    importer=game_data_importer(),\n",
    "    drift_splitter=date_based_splitter(SplitConfig(date_split=CURRYS_THREE_POINTER, columns=['FG3M'])),\n",
    "    drift_detector=evidently_drift_detector,\n",
    ")\n",
    "\n",
    "eda_pipeline.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d931d2a",
   "metadata": {},
   "source": [
    "## Post-execution: Fetching pipelines and reviewing results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fdd46b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from zenml.integrations.evidently.visualizers import EvidentlyVisualizer\n",
    "from zenml.repository import Repository\n",
    "import json\n",
    "\n",
    "repo = Repository()\n",
    "p = repo.get_pipeline(pipeline_name='data_analysis_pipeline')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "901b1e81",
   "metadata": {},
   "outputs": [],
   "source": [
    "p.runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ac82274",
   "metadata": {},
   "outputs": [],
   "source": [
    "last_run = p.runs[-1]\n",
    "last_run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8bf612a",
   "metadata": {},
   "outputs": [],
   "source": [
    "drift_detection_step = last_run.get_step(\n",
    "    name=\"drift_detector\"\n",
    ")\n",
    "drift_detection_step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76582b33",
   "metadata": {},
   "outputs": [],
   "source": [
    "EvidentlyVisualizer().visualize(drift_detection_step)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc6eff38",
   "metadata": {},
   "source": [
    "# Chapter 2 - Training Pipeline "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b947723",
   "metadata": {},
   "source": [
    "![Training Pipeline](_assets/TrainingPipeline.png \"Planned Architecture\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9276c358",
   "metadata": {},
   "outputs": [],
   "source": [
    "!zenml integration install mlflow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "744b012e",
   "metadata": {},
   "source": [
    "![Mlflow](_assets/zenml+evidently+mlflow.png \"MLFlow\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "976de746",
   "metadata": {},
   "outputs": [],
   "source": [
    "!zenml integration install kubeflow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "696d74c1",
   "metadata": {},
   "source": [
    "![All](_assets/evidently+mlflow+discord+kubeflow.png \"All\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b3206b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import date, timedelta\n",
    "from zenml.pipelines import pipeline\n",
    "from zenml.integrations.mlflow.mlflow_utils import (\n",
    "    enable_mlflow,\n",
    "    local_mlflow_backend,\n",
    ")\n",
    "\n",
    "@enable_mlflow\n",
    "@pipeline\n",
    "def training_pipeline(\n",
    "        importer,\n",
    "        feature_engineerer,\n",
    "        encoder,\n",
    "        ml_splitter,\n",
    "        trainer,\n",
    "        tester,\n",
    "        drift_splitter,\n",
    "        drift_detector,\n",
    "        drift_alert\n",
    "):\n",
    "    \"\"\"Links all the steps together in a pipeline\"\"\"\n",
    "    # Data Preprocessing\n",
    "    raw_data = importer()\n",
    "    transformed_data = feature_engineerer(raw_data)\n",
    "    encoded_data, le_seasons, ohe_teams = encoder(transformed_data)\n",
    "    train_df_x, train_df_y, test_df_x, test_df_y, eval_df_x, eval_df_y = ml_splitter(encoded_data)\n",
    "    \n",
    "    # Model training\n",
    "    model = trainer(train_df_x, train_df_y, eval_df_x, eval_df_y)\n",
    "    test_results = tester(model, test_df_x, test_df_y)\n",
    "\n",
    "    # drift detection branch\n",
    "    reference_dataset, comparison_dataset = drift_splitter(raw_data)\n",
    "    drift_report, _ = drift_detector(reference_dataset, comparison_dataset)\n",
    "    drift_alert(drift_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "506a34a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.base import RegressorMixin\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import mlflow\n",
    "\n",
    "from zenml.steps import step\n",
    "from zenml.steps.base_step_config import BaseStepConfig\n",
    "\n",
    "\n",
    "class RandomForestTrainerConfig(BaseStepConfig):\n",
    "    \"\"\"Config class for the sklearn trainer\"\"\"\n",
    "    max_depth: int = 10000\n",
    "    target_col: str = 'FG3M'\n",
    "\n",
    "\n",
    "@step(enable_cache=False)\n",
    "def random_forest_trainer(train_df_x: pd.DataFrame, train_df_y: pd.DataFrame,\n",
    "                          eval_df_x: pd.DataFrame, eval_df_y: pd.DataFrame,\n",
    "                          config: RandomForestTrainerConfig) -> RegressorMixin:\n",
    "\n",
    "    mlflow.sklearn.autolog()\n",
    "    clf = RandomForestRegressor(max_depth=config.max_depth)\n",
    "    clf.fit(train_df_x, np.squeeze(train_df_y.values.T))\n",
    "    eval_score = clf.score(eval_df_x, np.squeeze(eval_df_y.values.T))\n",
    "    print(f\"Eval score is: {eval_score}\")\n",
    "    return clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cf796b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from steps.analyzer import analyze_drift\n",
    "from steps.encoder import data_encoder\n",
    "from steps.evaluator import tester\n",
    "from steps.feature_engineer import feature_engineer\n",
    "from steps.importer import game_data_importer\n",
    "from steps.splitter import sklearn_splitter, SklearnSplitterConfig, reference_data_splitter, TrainingSplitConfig\n",
    "from steps.discord_bot import discord_alert\n",
    "\n",
    "ONE_WEEK_AGO = (date.today() - timedelta(days=7)).strftime(\"%Y-%m-%d\")\n",
    "\n",
    "\n",
    "# Initialize the pipeline\n",
    "train_pipeline = training_pipeline(\n",
    "    # Data Wrangling\n",
    "    importer=game_data_importer(),\n",
    "    feature_engineerer=feature_engineer(),\n",
    "    encoder=data_encoder(),\n",
    "    ml_splitter=sklearn_splitter(SklearnSplitterConfig(ratios={'train': 0.6, 'test': 0.2, 'validation': 0.2})),\n",
    "    \n",
    "    # Model training\n",
    "    trainer=random_forest_trainer(),\n",
    "    tester=tester(),\n",
    "    \n",
    "    # Drift detection\n",
    "    drift_splitter=reference_data_splitter(\n",
    "        TrainingSplitConfig(\n",
    "            new_data_split_date=ONE_WEEK_AGO,\n",
    "            start_reference_time_frame=CURRYS_THREE_POINTER,\n",
    "            end_reference_time_frame=ONE_WEEK_AGO,\n",
    "            columns=[\"FG3M\"])),\n",
    "    \n",
    "    drift_detector=EvidentlyProfileStep(\n",
    "        EvidentlyProfileConfig(\n",
    "            column_mapping=None,\n",
    "            profile_sections=[\"datadrift\"])),\n",
    "    \n",
    "    # Alert discord\n",
    "    drift_alert=discord_alert(),\n",
    ")\n",
    "\n",
    "train_pipeline.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b477d16",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!mlflow ui --backend-store-uri {local_mlflow_backend()} --port 4999"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7bd0927",
   "metadata": {},
   "outputs": [],
   "source": [
    "from zenml.integrations.evidently.visualizers import EvidentlyVisualizer\n",
    "from zenml.repository import Repository\n",
    "\n",
    "\n",
    "last_week = date.today() - timedelta(days=7)\n",
    "ONE_WEEK_AGO = last_week.strftime(\"%Y-%m-%d\")\n",
    "CURRY_FROM_DOWNTOWN = '2016-02-27'\n",
    "\n",
    "\n",
    "repo = Repository()\n",
    "p = repo.get_pipeline(pipeline_name='training_pipeline')\n",
    "last_run = p.runs[-1]\n",
    "drift_analysis_step = last_run.get_step(\n",
    "    name=\"drift_alert\"\n",
    ")\n",
    "print(f'Data drift detected: {drift_analysis_step.output.read()}')\n",
    "\n",
    "drift_detection_step = last_run.get_step(\n",
    "    name=\"drift_detector\"\n",
    ")\n",
    "evidently_outputs = drift_detection_step\n",
    "\n",
    "EvidentlyVisualizer().visualize(evidently_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc1c4c3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "!zenml stack list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "399e7169",
   "metadata": {},
   "source": [
    "## Zenml Stacks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b81cf8f",
   "metadata": {},
   "source": [
    "### From Local\n",
    "\n",
    "![LocalStack](_assets/localstack.png \"LocalStack\")\n",
    "\n",
    "### To Kubeflow\n",
    "\n",
    "![KubeflowStack](_assets/localstack-with-kubeflow-orchestrator.png \"KubeflowStack\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ed715ba3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/hamza/.virtualenvs/zenml_dev/lib/python3.8/site-packages/pandas/compat/__init__.py:120: UserWarning: Could not import the lzma module. Your installed Python is incomplete. Attempting to use lzma compression will result in a RuntimeError.\n",
      "  warnings.warn(msg)\n",
      "\u001b[1;35mRegistered stack component with name 'local_registry'.\u001b[0m\n",
      "\u001b[32mSuccessfully registered container registry `local_registry`.\u001b[0m\n",
      "/home/hamza/.virtualenvs/zenml_dev/lib/python3.8/site-packages/pandas/compat/__init__.py:120: UserWarning: Could not import the lzma module. Your installed Python is incomplete. Attempting to use lzma compression will result in a RuntimeError.\n",
      "  warnings.warn(msg)\n",
      "\u001b[1;35mRegistered stack component with name 'kubeflow_orchestrator'.\u001b[0m\n",
      "\u001b[32mSuccessfully registered orchestrator `kubeflow_orchestrator`.\u001b[0m\n",
      "/home/hamza/.virtualenvs/zenml_dev/lib/python3.8/site-packages/pandas/compat/__init__.py:120: UserWarning: Could not import the lzma module. Your installed Python is incomplete. Attempting to use lzma compression will result in a RuntimeError.\n",
      "  warnings.warn(msg)\n",
      "\u001b[1;35mRegistered stack with name 'local_kubeflow_stack'.\u001b[0m\n",
      "\u001b[32mStack `local_kubeflow_stack` successfully registered!\u001b[0m\n",
      "\u001b[32mActive stack: local_kubeflow_stack\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!zenml container-registry register local_registry --type=default --uri=localhost:5000\n",
    "!zenml orchestrator register kubeflow_orchestrator --type=kubeflow\n",
    "!zenml stack register local_kubeflow_stack \\\n",
    "    -m local_metadata_store \\\n",
    "    -a local_artifact_store \\\n",
    "    -o kubeflow_orchestrator \\\n",
    "    -c local_registry\n",
    "\n",
    "# Activate the newly created stack\n",
    "!zenml stack set local_kubeflow_stack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "713d2ddc",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/hamza/.virtualenvs/zenml_dev/lib/python3.8/site-packages/pandas/compat/__init__.py:120: UserWarning: Could not import the lzma module. Your installed Python is incomplete. Attempting to use lzma compression will result in a RuntimeError.\n",
      "  warnings.warn(msg)\n",
      "\u001b[32mProvisioning resources for stack 'local_kubeflow_stack'.\u001b[0m\n",
      "\u001b[1;35mProvisioning resources for stack 'local_kubeflow_stack'.\u001b[0m\n",
      "\u001b[1;35mProvisioning local Kubeflow Pipelines deployment...\u001b[0m\n",
      "\u001b[1;35mCreating local K3D cluster 'zenml-kubeflow-edfcfa45'.\u001b[0m\n",
      "\u001b[33mWARN\u001b[0m[0000] No node filter specified                     \n",
      "\u001b[36mINFO\u001b[0m[0000] Prep: Network                                \n",
      "\u001b[36mINFO\u001b[0m[0000] Created network 'k3d-zenml-kubeflow-edfcfa45' \n",
      "\u001b[36mINFO\u001b[0m[0000] Created volume 'k3d-zenml-kubeflow-edfcfa45-images' \n",
      "\u001b[36mINFO\u001b[0m[0000] Creating node 'k3d-zenml-kubeflow-registry.localhost' \n",
      "\u001b[36mINFO\u001b[0m[0000] Successfully created registry 'k3d-zenml-kubeflow-registry.localhost' \n",
      "\u001b[36mINFO\u001b[0m[0000] Starting new tools node...                   \n",
      "\u001b[36mINFO\u001b[0m[0000] Starting Node 'k3d-zenml-kubeflow-edfcfa45-tools' \n",
      "\u001b[36mINFO\u001b[0m[0001] Creating node 'k3d-zenml-kubeflow-edfcfa45-server-0' \n",
      "\u001b[36mINFO\u001b[0m[0001] Creating LoadBalancer 'k3d-zenml-kubeflow-edfcfa45-serverlb' \n",
      "\u001b[36mINFO\u001b[0m[0001] Using the k3d-tools node to gather environment information \n",
      "\u001b[36mINFO\u001b[0m[0001] HostIP: using network gateway 172.26.0.1 address \n",
      "\u001b[36mINFO\u001b[0m[0001] Starting cluster 'zenml-kubeflow-edfcfa45'   \n",
      "\u001b[36mINFO\u001b[0m[0001] Starting servers...                          \n",
      "\u001b[36mINFO\u001b[0m[0002] Starting Node 'k3d-zenml-kubeflow-edfcfa45-server-0' \n",
      "\u001b[36mINFO\u001b[0m[0008] All agents already running.                  \n",
      "\u001b[36mINFO\u001b[0m[0008] Starting helpers...                          \n",
      "\u001b[36mINFO\u001b[0m[0008] Starting Node 'k3d-zenml-kubeflow-registry.localhost' \n",
      "\u001b[36mINFO\u001b[0m[0009] Starting Node 'k3d-zenml-kubeflow-edfcfa45-serverlb' \n",
      "\u001b[36mINFO\u001b[0m[0017] Injecting '172.26.0.1 host.k3d.internal' into /etc/hosts of all nodes... \n",
      "\u001b[36mINFO\u001b[0m[0017] Injecting records for host.k3d.internal and for 3 network members into CoreDNS configmap... \n",
      "\u001b[36mINFO\u001b[0m[0020] Cluster 'zenml-kubeflow-edfcfa45' created successfully! \n",
      "\u001b[36mINFO\u001b[0m[0020] You can now use it like this:                \n",
      "kubectl cluster-info\n",
      "\u001b[1;35mFinished K3D cluster creation.\u001b[0m\n",
      "\u001b[1;35mDeploying Kubeflow Pipelines.\u001b[0m\n",
      "namespace/kubeflow created\n",
      "customresourcedefinition.apiextensions.k8s.io/clusterworkflowtemplates.argoproj.io created\n",
      "customresourcedefinition.apiextensions.k8s.io/cronworkflows.argoproj.io created\n",
      "customresourcedefinition.apiextensions.k8s.io/workfloweventbindings.argoproj.io created\n",
      "customresourcedefinition.apiextensions.k8s.io/workflows.argoproj.io created\n",
      "customresourcedefinition.apiextensions.k8s.io/workflowtemplates.argoproj.io created\n",
      "\u001b[33;1mWarning:\u001b[0m apiextensions.k8s.io/v1beta1 CustomResourceDefinition is deprecated in v1.16+, unavailable in v1.22+; use apiextensions.k8s.io/v1 CustomResourceDefinition\n",
      "customresourcedefinition.apiextensions.k8s.io/applications.app.k8s.io created\n",
      "customresourcedefinition.apiextensions.k8s.io/scheduledworkflows.kubeflow.org created\n",
      "customresourcedefinition.apiextensions.k8s.io/viewers.kubeflow.org created\n",
      "serviceaccount/kubeflow-pipelines-cache-deployer-sa created\n",
      "clusterrole.rbac.authorization.k8s.io/kubeflow-pipelines-cache-deployer-clusterrole created\n",
      "clusterrolebinding.rbac.authorization.k8s.io/kubeflow-pipelines-cache-deployer-clusterrolebinding created\n",
      "customresourcedefinition.apiextensions.k8s.io/applications.app.k8s.io condition met\n",
      "I0126 17:37:40.726717   28129 log.go:181] well-defined vars that were never replaced: kfp-app-name,kfp-app-version\n",
      "serviceaccount/argo created\n",
      "serviceaccount/kubeflow-pipelines-cache created\n",
      "serviceaccount/kubeflow-pipelines-container-builder created\n",
      "serviceaccount/kubeflow-pipelines-metadata-writer created\n",
      "serviceaccount/kubeflow-pipelines-viewer created\n",
      "serviceaccount/metadata-grpc-server created\n",
      "serviceaccount/ml-pipeline-persistenceagent created\n",
      "serviceaccount/ml-pipeline-scheduledworkflow created\n",
      "serviceaccount/ml-pipeline-ui created\n",
      "serviceaccount/ml-pipeline-viewer-crd-service-account created\n",
      "serviceaccount/ml-pipeline-visualizationserver created\n",
      "serviceaccount/ml-pipeline created\n",
      "serviceaccount/mysql created\n",
      "serviceaccount/pipeline-runner created\n",
      "role.rbac.authorization.k8s.io/argo-role created\n",
      "role.rbac.authorization.k8s.io/kubeflow-pipelines-cache-deployer-role created\n",
      "role.rbac.authorization.k8s.io/kubeflow-pipelines-cache-role created\n",
      "role.rbac.authorization.k8s.io/kubeflow-pipelines-metadata-writer-role created\n",
      "role.rbac.authorization.k8s.io/ml-pipeline-persistenceagent-role created\n",
      "role.rbac.authorization.k8s.io/ml-pipeline-scheduledworkflow-role created\n",
      "role.rbac.authorization.k8s.io/ml-pipeline-ui created\n",
      "role.rbac.authorization.k8s.io/ml-pipeline-viewer-controller-role created\n",
      "role.rbac.authorization.k8s.io/ml-pipeline created\n",
      "role.rbac.authorization.k8s.io/pipeline-runner created\n",
      "rolebinding.rbac.authorization.k8s.io/argo-binding created\n",
      "rolebinding.rbac.authorization.k8s.io/kubeflow-pipelines-cache-binding created\n",
      "rolebinding.rbac.authorization.k8s.io/kubeflow-pipelines-cache-deployer-rolebinding created\n",
      "rolebinding.rbac.authorization.k8s.io/kubeflow-pipelines-metadata-writer-binding created\n",
      "rolebinding.rbac.authorization.k8s.io/ml-pipeline-persistenceagent-binding created\n",
      "rolebinding.rbac.authorization.k8s.io/ml-pipeline-scheduledworkflow-binding created\n",
      "rolebinding.rbac.authorization.k8s.io/ml-pipeline-ui created\n",
      "rolebinding.rbac.authorization.k8s.io/ml-pipeline-viewer-crd-binding created\n",
      "rolebinding.rbac.authorization.k8s.io/ml-pipeline created\n",
      "rolebinding.rbac.authorization.k8s.io/pipeline-runner-binding created\n",
      "configmap/kfp-launcher created\n",
      "configmap/metadata-grpc-configmap created\n",
      "configmap/ml-pipeline-ui-configmap created\n",
      "configmap/pipeline-install-config created\n",
      "configmap/workflow-controller-configmap created\n",
      "secret/mlpipeline-minio-artifact created\n",
      "secret/mysql-secret created\n",
      "service/cache-server created\n",
      "service/metadata-envoy-service created\n",
      "service/metadata-grpc-service created\n",
      "service/minio-service created\n",
      "service/ml-pipeline-ui created\n",
      "service/ml-pipeline-visualizationserver created\n",
      "service/ml-pipeline created\n",
      "service/mysql created\n",
      "service/workflow-controller-metrics created\n",
      "deployment.apps/cache-deployer-deployment created\n",
      "deployment.apps/cache-server created\n",
      "deployment.apps/metadata-envoy-deployment created\n",
      "deployment.apps/metadata-grpc-deployment created\n",
      "deployment.apps/metadata-writer created\n",
      "deployment.apps/minio created\n",
      "deployment.apps/ml-pipeline-persistenceagent created\n",
      "deployment.apps/ml-pipeline-scheduledworkflow created\n",
      "deployment.apps/ml-pipeline-ui created\n",
      "deployment.apps/ml-pipeline-viewer-crd created\n",
      "deployment.apps/ml-pipeline-visualizationserver created\n",
      "deployment.apps/ml-pipeline created\n",
      "deployment.apps/mysql created\n",
      "deployment.apps/workflow-controller created\n",
      "persistentvolumeclaim/minio-pvc created\n",
      "persistentvolumeclaim/mysql-pv-claim created\n",
      "\u001b[1;35mWaiting for all Kubeflow Pipelines pods to be ready (this might take a few minutes).\u001b[0m\n",
      "\u001b[1;35mCurrent pod status:\u001b[0m\n",
      "NAME                                            READY   STATUS              RESTARTS   AGE\n",
      "cache-server-55897df854-8vrlz                   0/1     ContainerCreating   0          1s\n",
      "cache-deployer-deployment-d95f8b79f-qlfs8       0/1     ContainerCreating   0          1s\n",
      "metadata-grpc-deployment-6b5685488-jn7sx        0/1     Pending             0          1s\n",
      "metadata-envoy-deployment-5b587ff9d4-bqdcm      0/1     ContainerCreating   0          1s\n",
      "metadata-writer-5c84d65485-vdzgq                0/1     Pending             0          1s\n",
      "minio-5b65df66c9-cl84q                          0/1     Pending             0          0s\n",
      "ml-pipeline-persistenceagent-69bdb89cfc-tq4w6   0/1     Pending             0          0s\n",
      "ml-pipeline-scheduledworkflow-f45d59698-szdzs   0/1     Pending             0          0s\n",
      "\u001b[1;35mOne or more pods not ready yet, waiting for 30 seconds...\u001b[0m\n",
      "\u001b[1;35mCurrent pod status:\u001b[0m\n",
      "NAME                                              READY   STATUS              RESTARTS   AGE\n",
      "cache-server-55897df854-8vrlz                     0/1     ContainerCreating   0          32s\n",
      "cache-deployer-deployment-d95f8b79f-qlfs8         0/1     ContainerCreating   0          32s\n",
      "metadata-envoy-deployment-5b587ff9d4-bqdcm        0/1     ContainerCreating   0          32s\n",
      "minio-5b65df66c9-cl84q                            0/1     Pending             0          31s\n",
      "metadata-grpc-deployment-6b5685488-jn7sx          0/1     ContainerCreating   0          32s\n",
      "mysql-f7b9b7dd4-x6k7v                             0/1     Pending             0          30s\n",
      "metadata-writer-5c84d65485-vdzgq                  0/1     ContainerCreating   0          32s\n",
      "ml-pipeline-persistenceagent-69bdb89cfc-tq4w6     0/1     ContainerCreating   0          31s\n",
      "ml-pipeline-scheduledworkflow-f45d59698-szdzs     0/1     ContainerCreating   0          31s\n",
      "ml-pipeline-visualizationserver-75d8c8cd9-fkrqh   0/1     ContainerCreating   0          30s\n",
      "ml-pipeline-69c679bf86-wff88                      0/1     ContainerCreating   0          30s\n",
      "ml-pipeline-ui-78c69869b8-zs2hv                   0/1     ContainerCreating   0          31s\n",
      "ml-pipeline-viewer-crd-6d4dc67b48-cgpzd           0/1     ContainerCreating   0          31s\n",
      "workflow-controller-99b6487-vqnph                 0/1     ContainerCreating   0          30s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;35mOne or more pods not ready yet, waiting for 30 seconds...\u001b[0m\n",
      "\u001b[1;35mCurrent pod status:\u001b[0m\n",
      "NAME                                              READY   STATUS              RESTARTS   AGE\n",
      "cache-server-55897df854-8vrlz                     0/1     ContainerCreating   0          63s\n",
      "cache-deployer-deployment-d95f8b79f-qlfs8         0/1     ContainerCreating   0          63s\n",
      "metadata-envoy-deployment-5b587ff9d4-bqdcm        0/1     ContainerCreating   0          63s\n",
      "metadata-grpc-deployment-6b5685488-jn7sx          0/1     ContainerCreating   0          63s\n",
      "metadata-writer-5c84d65485-vdzgq                  0/1     ContainerCreating   0          63s\n",
      "ml-pipeline-persistenceagent-69bdb89cfc-tq4w6     0/1     ContainerCreating   0          62s\n",
      "ml-pipeline-scheduledworkflow-f45d59698-szdzs     0/1     ContainerCreating   0          62s\n",
      "ml-pipeline-visualizationserver-75d8c8cd9-fkrqh   0/1     ContainerCreating   0          61s\n",
      "ml-pipeline-69c679bf86-wff88                      0/1     ContainerCreating   0          61s\n",
      "ml-pipeline-ui-78c69869b8-zs2hv                   0/1     ContainerCreating   0          62s\n",
      "workflow-controller-99b6487-vqnph                 0/1     ContainerCreating   0          61s\n",
      "mysql-f7b9b7dd4-x6k7v                             0/1     ContainerCreating   0          61s\n",
      "minio-5b65df66c9-cl84q                            0/1     ContainerCreating   0          62s\n",
      "ml-pipeline-viewer-crd-6d4dc67b48-cgpzd           1/1     Running             0          62s\n",
      "\u001b[1;35mOne or more pods not ready yet, waiting for 30 seconds...\u001b[0m\n",
      "\u001b[1;35mCurrent pod status:\u001b[0m\n",
      "NAME                                              READY   STATUS              RESTARTS   AGE\n",
      "cache-server-55897df854-8vrlz                     0/1     ContainerCreating   0          94s\n",
      "cache-deployer-deployment-d95f8b79f-qlfs8         0/1     ContainerCreating   0          94s\n",
      "metadata-envoy-deployment-5b587ff9d4-bqdcm        0/1     ContainerCreating   0          94s\n",
      "metadata-writer-5c84d65485-vdzgq                  0/1     ContainerCreating   0          94s\n",
      "ml-pipeline-visualizationserver-75d8c8cd9-fkrqh   0/1     ContainerCreating   0          92s\n",
      "ml-pipeline-69c679bf86-wff88                      0/1     ContainerCreating   0          92s\n",
      "ml-pipeline-ui-78c69869b8-zs2hv                   0/1     ContainerCreating   0          93s\n",
      "mysql-f7b9b7dd4-x6k7v                             0/1     ContainerCreating   0          92s\n",
      "minio-5b65df66c9-cl84q                            0/1     ContainerCreating   0          93s\n",
      "ml-pipeline-viewer-crd-6d4dc67b48-cgpzd           1/1     Running             0          93s\n",
      "ml-pipeline-scheduledworkflow-f45d59698-szdzs     1/1     Running             0          93s\n",
      "ml-pipeline-persistenceagent-69bdb89cfc-tq4w6     1/1     Running             0          93s\n",
      "metadata-grpc-deployment-6b5685488-jn7sx          0/1     Running             0          94s\n",
      "workflow-controller-99b6487-vqnph                 1/1     Running             0          92s\n",
      "\u001b[1;35mOne or more pods not ready yet, waiting for 30 seconds...\u001b[0m\n",
      "\u001b[1;35mCurrent pod status:\u001b[0m\n",
      "NAME                                              READY   STATUS              RESTARTS   AGE\n",
      "cache-server-55897df854-8vrlz                     0/1     ContainerCreating   0          2m5s\n",
      "cache-deployer-deployment-d95f8b79f-qlfs8         0/1     ContainerCreating   0          2m5s\n",
      "metadata-writer-5c84d65485-vdzgq                  0/1     ContainerCreating   0          2m5s\n",
      "ml-pipeline-visualizationserver-75d8c8cd9-fkrqh   0/1     ContainerCreating   0          2m3s\n",
      "mysql-f7b9b7dd4-x6k7v                             0/1     ContainerCreating   0          2m3s\n",
      "minio-5b65df66c9-cl84q                            0/1     ContainerCreating   0          2m4s\n",
      "ml-pipeline-viewer-crd-6d4dc67b48-cgpzd           1/1     Running             0          2m4s\n",
      "ml-pipeline-scheduledworkflow-f45d59698-szdzs     1/1     Running             0          2m4s\n",
      "ml-pipeline-persistenceagent-69bdb89cfc-tq4w6     1/1     Running             0          2m4s\n",
      "metadata-grpc-deployment-6b5685488-jn7sx          0/1     Running             0          2m5s\n",
      "workflow-controller-99b6487-vqnph                 1/1     Running             0          2m3s\n",
      "ml-pipeline-ui-78c69869b8-zs2hv                   1/1     Running             0          2m4s\n",
      "metadata-envoy-deployment-5b587ff9d4-bqdcm        1/1     Running             0          2m5s\n",
      "ml-pipeline-69c679bf86-wff88                      0/1     Running             0          2m3s\n",
      "\u001b[1;35mOne or more pods not ready yet, waiting for 30 seconds...\u001b[0m\n",
      "\u001b[1;35mCurrent pod status:\u001b[0m\n",
      "NAME                                              READY   STATUS              RESTARTS   AGE\n",
      "cache-server-55897df854-8vrlz                     0/1     ContainerCreating   0          2m36s\n",
      "cache-deployer-deployment-d95f8b79f-qlfs8         0/1     ContainerCreating   0          2m36s\n",
      "metadata-writer-5c84d65485-vdzgq                  0/1     ContainerCreating   0          2m36s\n",
      "ml-pipeline-visualizationserver-75d8c8cd9-fkrqh   0/1     ContainerCreating   0          2m34s\n",
      "mysql-f7b9b7dd4-x6k7v                             0/1     ContainerCreating   0          2m34s\n",
      "minio-5b65df66c9-cl84q                            0/1     ContainerCreating   0          2m35s\n",
      "ml-pipeline-viewer-crd-6d4dc67b48-cgpzd           1/1     Running             0          2m35s\n",
      "ml-pipeline-scheduledworkflow-f45d59698-szdzs     1/1     Running             0          2m35s\n",
      "ml-pipeline-persistenceagent-69bdb89cfc-tq4w6     1/1     Running             0          2m35s\n",
      "workflow-controller-99b6487-vqnph                 1/1     Running             0          2m34s\n",
      "ml-pipeline-ui-78c69869b8-zs2hv                   1/1     Running             0          2m35s\n",
      "metadata-envoy-deployment-5b587ff9d4-bqdcm        1/1     Running             0          2m36s\n",
      "ml-pipeline-69c679bf86-wff88                      0/1     Running             0          2m34s\n",
      "metadata-grpc-deployment-6b5685488-jn7sx          0/1     Running             1          2m36s\n",
      "\u001b[1;35mOne or more pods not ready yet, waiting for 30 seconds...\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!zenml stack up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "296a2143",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!zenml stack set local_kubeflow_stack\n",
    "# Lets train within kubeflow pipelines\n",
    "!python run_pipeline.py train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf530aa6",
   "metadata": {},
   "source": [
    "# Chapter 3 - The Prediction Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b3ee8ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's return to our local stack\n",
    "!zenml stack set local_stack"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec9d6e37",
   "metadata": {},
   "source": [
    "![Training And Inference Pipeline](_assets/Training%20and%20Inference%20Pipeline.png \"Planned Architecture Full\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31d3c085",
   "metadata": {},
   "outputs": [],
   "source": [
    "from zenml.pipelines import pipeline\n",
    "\n",
    "\n",
    "@pipeline(enable_cache=False)\n",
    "def inference_pipeline(\n",
    "        importer,\n",
    "        preprocessor,\n",
    "        extract_next_week,\n",
    "        model_picker,\n",
    "        predictor,\n",
    "        post_processor\n",
    "):\n",
    "    \"\"\"Links all the steps together in a pipeline\"\"\"\n",
    "    season_schedule = importer()\n",
    "    processed_season_schedule = preprocessor(season_schedule)\n",
    "    upcoming_week = extract_next_week(processed_season_schedule)\n",
    "    model, run_id = model_picker()\n",
    "    predictions = predictor(model, upcoming_week)\n",
    "    readable_predictions = post_processor(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9d33ef2",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from steps.encoder import encode_columns_and_clean\n",
    "from steps.importer import import_season_schedule, SeasonScheduleConfig\n",
    "from steps.model_picker import model_picker\n",
    "from steps.predictor import predictor\n",
    "from steps.splitter import get_coming_week_data, TimeWindowConfig\n",
    "from steps.post_processor import data_post_processor\n",
    "\n",
    "# Initialize the pipeline\n",
    "inference_pipe = inference_pipeline(\n",
    "    importer=import_season_schedule(\n",
    "        SeasonScheduleConfig(current_season='2021-22')),\n",
    "    preprocessor=encode_columns_and_clean(),\n",
    "    extract_next_week=get_coming_week_data(TimeWindowConfig(time_window=7)),\n",
    "    model_picker=model_picker(),\n",
    "    predictor=predictor(),\n",
    "    post_processor=data_post_processor()\n",
    ")\n",
    "\n",
    "inference_pipe.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5b423e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets have a look at some of our predictions\n",
    "from zenml.repository import Repository\n",
    "\n",
    "r = Repository()\n",
    "df = r.get_pipeline(pipeline_name='inference_pipeline').runs[-1].steps[-1].output.read()\n",
    "df.head(20)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
