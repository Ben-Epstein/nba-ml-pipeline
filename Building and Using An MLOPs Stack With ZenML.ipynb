{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "27e6faed",
   "metadata": {},
   "source": [
    "![ZenML](_assets/Logo/zenml.svg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8585ad8e",
   "metadata": {},
   "source": [
    "https://github.com/zenml-io/nba-ml-pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c4de5a07",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8eaaa90",
   "metadata": {},
   "source": [
    "# Why ZenML"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87fde8c7",
   "metadata": {},
   "source": [
    "![Sam](_assets/sam.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e74ddf61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mInitializing ZenML repository at /home/hamza/temp_stuff/zenml_demo/nba-ml-pipeline.\u001b[0m\n",
      "/home/hamza/.virtualenvs/zenml_dev/lib/python3.8/site-packages/pandas/compat/__init__.py:120: UserWarning: Could not import the lzma module. Your installed Python is incomplete. Attempting to use lzma compression will result in a RuntimeError.\n",
      "  warnings.warn(msg)\n",
      "\u001b[1;35mRegistered stack component with name 'local_orchestrator'.\u001b[0m\n",
      "\u001b[1;35mRegistered stack component with name 'local_metadata_store'.\u001b[0m\n",
      "\u001b[1;35mRegistered stack component with name 'local_artifact_store'.\u001b[0m\n",
      "\u001b[1;35mRegistered stack with name 'local_stack'.\u001b[0m\n",
      "\u001b[32mZenML repository initialized at /home/hamza/temp_stuff/zenml_demo/nba-ml-pipeline.\u001b[0m\n",
      "\u001b[32mActive stack: local_stack\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!zenml init\n",
    "!zenml stack set local_stack"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a16c02d0",
   "metadata": {},
   "source": [
    "# Chapter 1 - Exploring NBA Data\n",
    "## Did Steph Curry Change the Game?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "531ddbed",
   "metadata": {},
   "source": [
    "https://www.youtube.com/watch?v=GEMVGHoenXM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e4108c6",
   "metadata": {},
   "source": [
    "![Steph Curry Drains the Game Winner vs Oklahoma City](https://i.makeagif.com/media/3-20-2016/7N5RWB.gif)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f52add8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We'll use this date in our pipelines\n",
    "CURRYS_THREE_POINTER = '2016-02-27'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e09e2f66",
   "metadata": {},
   "source": [
    "![PipelineStructure](_assets/DriftDetectionPipeline.png \"PipelineStructure\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27700042",
   "metadata": {},
   "source": [
    "## Creating our first step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f57f2a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reference\n",
    "from zenml.steps import step\n",
    "from steps.importer import ImporterConfig\n",
    "import pandas as pd\n",
    "\n",
    "@step\n",
    "def game_data_importer(config: ImporterConfig) -> pd.DataFrame:\n",
    "    \"\"\"Downloads season data from NBA API and returns a pd.DataFrame\"\"\"\n",
    "    dataframes = []\n",
    "    for season in config.seasons:\n",
    "        print(f\"Fetching data for season: {season}\")\n",
    "        dataframes.append(leaguegamelog.LeagueGameLog(season=season, timeout=180).get_data_frames()[0])\n",
    "        # sleep so as not to bomb api server :-)\n",
    "        time.sleep(2)\n",
    "    return pd.concat(dataframes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce8e0cb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Import our steps\n",
    "from steps.importer import game_data_importer\n",
    "from steps.splitter import date_based_splitter, SplitConfig"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1627c7c5",
   "metadata": {},
   "source": [
    "## Creating an exploratory pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1225c6eb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from zenml.pipelines import pipeline\n",
    "\n",
    "@pipeline\n",
    "def data_analysis_pipeline(\n",
    "        importer,          # Import NBA game data\n",
    "        drift_splitter,    # Split data at relevant date\n",
    "        drift_detector,    # Compare data distributions\n",
    "):\n",
    "    \"\"\"Links all the steps together in a pipeline\"\"\"\n",
    "    raw_data = importer()\n",
    "    reference_dataset, comparison_dataset = drift_splitter(raw_data)\n",
    "    drift_report, _ = drift_detector(reference_dataset, comparison_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34b92917",
   "metadata": {},
   "source": [
    "https://blog.zenml.io/zenml-loves-evidently/  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01338745",
   "metadata": {},
   "source": [
    "![Evidently](_assets/zenml+evidently.png \"Evidently\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aaa3006",
   "metadata": {},
   "outputs": [],
   "source": [
    "!zenml integration install evidently"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "734be408",
   "metadata": {},
   "outputs": [],
   "source": [
    "from zenml.integrations.evidently.steps import (\n",
    "    EvidentlyProfileConfig,\n",
    "    EvidentlyProfileStep,\n",
    ")\n",
    "\n",
    "evidently_drift_detector = EvidentlyProfileStep(\n",
    "    EvidentlyProfileConfig(\n",
    "        column_mapping=None,\n",
    "        profile_sections=[\"datadrift\"],\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42cdb618",
   "metadata": {},
   "source": [
    "### Run the pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d019fff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the pipeline\n",
    "eda_pipeline = data_analysis_pipeline(\n",
    "    importer=game_data_importer(),\n",
    "    drift_splitter=date_based_splitter(SplitConfig(date_split=CURRYS_THREE_POINTER, columns=['FG3M'])),\n",
    "    drift_detector=evidently_drift_detector,\n",
    ")\n",
    "\n",
    "eda_pipeline.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d931d2a",
   "metadata": {},
   "source": [
    "## Post-execution: Fetching pipelines and reviewing results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fdd46b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from zenml.integrations.evidently.visualizers import EvidentlyVisualizer\n",
    "from zenml.repository import Repository\n",
    "import json\n",
    "\n",
    "repo = Repository()\n",
    "p = repo.get_pipeline(pipeline_name='data_analysis_pipeline')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "901b1e81",
   "metadata": {},
   "outputs": [],
   "source": [
    "p.runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ac82274",
   "metadata": {},
   "outputs": [],
   "source": [
    "last_run = p.runs[-1]\n",
    "last_run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8bf612a",
   "metadata": {},
   "outputs": [],
   "source": [
    "drift_detection_step = last_run.get_step(\n",
    "    name=\"drift_detector\"\n",
    ")\n",
    "drift_detection_step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76582b33",
   "metadata": {},
   "outputs": [],
   "source": [
    "EvidentlyVisualizer().visualize(drift_detection_step)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc6eff38",
   "metadata": {},
   "source": [
    "# Chapter 2 - Training Pipeline "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b947723",
   "metadata": {},
   "source": [
    "![Training Pipeline](_assets/TrainingPipeline.png \"Planned Architecture\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9276c358",
   "metadata": {},
   "outputs": [],
   "source": [
    "!zenml integration install mlflow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "744b012e",
   "metadata": {},
   "source": [
    "![Mlflow](_assets/zenml+evidently+mlflow.png \"MLFlow\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "976de746",
   "metadata": {},
   "outputs": [],
   "source": [
    "!zenml integration install kubeflow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "696d74c1",
   "metadata": {},
   "source": [
    "![All](_assets/evidently+mlflow+discord+kubeflow.png \"All\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b3206b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import date, timedelta\n",
    "from zenml.pipelines import pipeline\n",
    "from zenml.integrations.mlflow.mlflow_utils import (\n",
    "    enable_mlflow,\n",
    "    local_mlflow_backend,\n",
    ")\n",
    "\n",
    "@enable_mlflow\n",
    "@pipeline\n",
    "def training_pipeline(\n",
    "        importer,\n",
    "        feature_engineerer,\n",
    "        encoder,\n",
    "        ml_splitter,\n",
    "        trainer,\n",
    "        tester,\n",
    "        drift_splitter,\n",
    "        drift_detector,\n",
    "        drift_alert\n",
    "):\n",
    "    \"\"\"Links all the steps together in a pipeline\"\"\"\n",
    "    # Data Preprocessing\n",
    "    raw_data = importer()\n",
    "    transformed_data = feature_engineerer(raw_data)\n",
    "    encoded_data, le_seasons, ohe_teams = encoder(transformed_data)\n",
    "    train_df_x, train_df_y, test_df_x, test_df_y, eval_df_x, eval_df_y = ml_splitter(encoded_data)\n",
    "    \n",
    "    # Model training\n",
    "    model = trainer(train_df_x, train_df_y, eval_df_x, eval_df_y)\n",
    "    test_results = tester(model, test_df_x, test_df_y)\n",
    "\n",
    "    # drift detection branch\n",
    "    reference_dataset, comparison_dataset = drift_splitter(raw_data)\n",
    "    drift_report, _ = drift_detector(reference_dataset, comparison_dataset)\n",
    "    drift_alert(drift_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "506a34a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.base import RegressorMixin\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import mlflow\n",
    "\n",
    "from zenml.steps import step\n",
    "from zenml.steps.base_step_config import BaseStepConfig\n",
    "\n",
    "\n",
    "class RandomForestTrainerConfig(BaseStepConfig):\n",
    "    \"\"\"Config class for the sklearn trainer\"\"\"\n",
    "    max_depth: int = 10000\n",
    "    target_col: str = 'FG3M'\n",
    "\n",
    "\n",
    "@step(enable_cache=False)\n",
    "def random_forest_trainer(train_df_x: pd.DataFrame, train_df_y: pd.DataFrame,\n",
    "                          eval_df_x: pd.DataFrame, eval_df_y: pd.DataFrame,\n",
    "                          config: RandomForestTrainerConfig) -> RegressorMixin:\n",
    "\n",
    "    mlflow.sklearn.autolog()\n",
    "    clf = RandomForestRegressor(max_depth=config.max_depth)\n",
    "    clf.fit(train_df_x, np.squeeze(train_df_y.values.T))\n",
    "    eval_score = clf.score(eval_df_x, np.squeeze(eval_df_y.values.T))\n",
    "    print(f\"Eval score is: {eval_score}\")\n",
    "    return clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cf796b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from steps.analyzer import analyze_drift\n",
    "from steps.encoder import data_encoder\n",
    "from steps.evaluator import tester\n",
    "from steps.feature_engineer import feature_engineer\n",
    "from steps.importer import game_data_importer\n",
    "from steps.splitter import sklearn_splitter, SklearnSplitterConfig, reference_data_splitter, TrainingSplitConfig\n",
    "from steps.discord_bot import discord_alert\n",
    "\n",
    "ONE_WEEK_AGO = (date.today() - timedelta(days=7)).strftime(\"%Y-%m-%d\")\n",
    "\n",
    "\n",
    "# Initialize the pipeline\n",
    "train_pipeline = training_pipeline(\n",
    "    # Data Wrangling\n",
    "    importer=game_data_importer(),\n",
    "    feature_engineerer=feature_engineer(),\n",
    "    encoder=data_encoder(),\n",
    "    ml_splitter=sklearn_splitter(SklearnSplitterConfig(ratios={'train': 0.6, 'test': 0.2, 'validation': 0.2})),\n",
    "    \n",
    "    # Model training\n",
    "    trainer=random_forest_trainer(),\n",
    "    tester=tester(),\n",
    "    \n",
    "    # Drift detection\n",
    "    drift_splitter=reference_data_splitter(\n",
    "        TrainingSplitConfig(\n",
    "            new_data_split_date=ONE_WEEK_AGO,\n",
    "            start_reference_time_frame=CURRYS_THREE_POINTER,\n",
    "            end_reference_time_frame=ONE_WEEK_AGO,\n",
    "            columns=[\"FG3M\"])),\n",
    "    \n",
    "    drift_detector=EvidentlyProfileStep(\n",
    "        EvidentlyProfileConfig(\n",
    "            column_mapping=None,\n",
    "            profile_sections=[\"datadrift\"])),\n",
    "    \n",
    "    # Alert discord\n",
    "    drift_alert=discord_alert(),\n",
    ")\n",
    "\n",
    "train_pipeline.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b477d16",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!mlflow ui --backend-store-uri {local_mlflow_backend()} --port 4999"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7bd0927",
   "metadata": {},
   "outputs": [],
   "source": [
    "from zenml.integrations.evidently.visualizers import EvidentlyVisualizer\n",
    "from zenml.repository import Repository\n",
    "\n",
    "\n",
    "last_week = date.today() - timedelta(days=7)\n",
    "ONE_WEEK_AGO = last_week.strftime(\"%Y-%m-%d\")\n",
    "CURRY_FROM_DOWNTOWN = '2016-02-27'\n",
    "\n",
    "\n",
    "repo = Repository()\n",
    "p = repo.get_pipeline(pipeline_name='training_pipeline')\n",
    "last_run = p.runs[-1]\n",
    "drift_analysis_step = last_run.get_step(\n",
    "    name=\"drift_alert\"\n",
    ")\n",
    "print(f'Data drift detected: {drift_analysis_step.output.read()}')\n",
    "\n",
    "drift_detection_step = last_run.get_step(\n",
    "    name=\"drift_detector\"\n",
    ")\n",
    "evidently_outputs = drift_detection_step\n",
    "\n",
    "EvidentlyVisualizer().visualize(evidently_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc1c4c3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "!zenml stack list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "399e7169",
   "metadata": {},
   "source": [
    "## Zenml Stacks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b81cf8f",
   "metadata": {},
   "source": [
    "### From Local\n",
    "\n",
    "![LocalStack](_assets/localstack.png \"LocalStack\")\n",
    "\n",
    "### To Kubeflow\n",
    "\n",
    "![KubeflowStack](_assets/localstack-with-kubeflow-orchestrator.png \"KubeflowStack\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ed715ba3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/hamza/.virtualenvs/zenml_dev/lib/python3.8/site-packages/pandas/compat/__init__.py:120: UserWarning: Could not import the lzma module. Your installed Python is incomplete. Attempting to use lzma compression will result in a RuntimeError.\n",
      "  warnings.warn(msg)\n",
      "\u001b[1;35mRegistered stack component with name 'local_registry'.\u001b[0m\n",
      "\u001b[32mSuccessfully registered container registry `local_registry`.\u001b[0m\n",
      "/home/hamza/.virtualenvs/zenml_dev/lib/python3.8/site-packages/pandas/compat/__init__.py:120: UserWarning: Could not import the lzma module. Your installed Python is incomplete. Attempting to use lzma compression will result in a RuntimeError.\n",
      "  warnings.warn(msg)\n",
      "\u001b[1;35mRegistered stack component with name 'kubeflow_orchestrator'.\u001b[0m\n",
      "\u001b[32mSuccessfully registered orchestrator `kubeflow_orchestrator`.\u001b[0m\n",
      "/home/hamza/.virtualenvs/zenml_dev/lib/python3.8/site-packages/pandas/compat/__init__.py:120: UserWarning: Could not import the lzma module. Your installed Python is incomplete. Attempting to use lzma compression will result in a RuntimeError.\n",
      "  warnings.warn(msg)\n",
      "\u001b[1;35mRegistered stack with name 'local_kubeflow_stack'.\u001b[0m\n",
      "\u001b[32mStack `local_kubeflow_stack` successfully registered!\u001b[0m\n",
      "\u001b[32mActive stack: local_kubeflow_stack\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!zenml container-registry register local_registry --type=default --uri=localhost:5000\n",
    "!zenml orchestrator register kubeflow_orchestrator --type=kubeflow\n",
    "!zenml stack register local_kubeflow_stack \\\n",
    "    -m local_metadata_store \\\n",
    "    -a local_artifact_store \\\n",
    "    -o kubeflow_orchestrator \\\n",
    "    -c local_registry\n",
    "\n",
    "# Activate the newly created stack\n",
    "!zenml stack set local_kubeflow_stack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "713d2ddc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/hamza/.virtualenvs/zenml_dev/lib/python3.8/site-packages/pandas/compat/__init__.py:120: UserWarning: Could not import the lzma module. Your installed Python is incomplete. Attempting to use lzma compression will result in a RuntimeError.\n",
      "  warnings.warn(msg)\n",
      "\u001b[32mProvisioning resources for stack 'local_kubeflow_stack'.\u001b[0m\n",
      "\u001b[1;35mProvisioning resources for stack 'local_kubeflow_stack'.\u001b[0m\n",
      "\u001b[1;35mProvisioning local Kubeflow Pipelines deployment...\u001b[0m\n",
      "\u001b[1;35mCreating local K3D cluster 'zenml-kubeflow-edfcfa45'.\u001b[0m\n",
      "\u001b[33mWARN\u001b[0m[0000] No node filter specified                     \n",
      "\u001b[36mINFO\u001b[0m[0000] Prep: Network                                \n",
      "\u001b[36mINFO\u001b[0m[0000] Created network 'k3d-zenml-kubeflow-edfcfa45' \n",
      "\u001b[36mINFO\u001b[0m[0000] Created volume 'k3d-zenml-kubeflow-edfcfa45-images' \n",
      "\u001b[36mINFO\u001b[0m[0000] Creating node 'k3d-zenml-kubeflow-registry.localhost' \n",
      "\u001b[36mINFO\u001b[0m[0000] Successfully created registry 'k3d-zenml-kubeflow-registry.localhost' \n",
      "\u001b[36mINFO\u001b[0m[0000] Starting new tools node...                   \n",
      "\u001b[36mINFO\u001b[0m[0000] Starting Node 'k3d-zenml-kubeflow-edfcfa45-tools' \n",
      "\u001b[36mINFO\u001b[0m[0001] Creating node 'k3d-zenml-kubeflow-edfcfa45-server-0' \n",
      "\u001b[36mINFO\u001b[0m[0001] Creating LoadBalancer 'k3d-zenml-kubeflow-edfcfa45-serverlb' \n",
      "\u001b[36mINFO\u001b[0m[0001] Using the k3d-tools node to gather environment information \n",
      "\u001b[36mINFO\u001b[0m[0001] HostIP: using network gateway 172.25.0.1 address \n",
      "\u001b[36mINFO\u001b[0m[0001] Starting cluster 'zenml-kubeflow-edfcfa45'   \n",
      "\u001b[36mINFO\u001b[0m[0001] Starting servers...                          \n",
      "\u001b[36mINFO\u001b[0m[0002] Starting Node 'k3d-zenml-kubeflow-edfcfa45-server-0' \n",
      "\u001b[36mINFO\u001b[0m[0009] All agents already running.                  \n",
      "\u001b[36mINFO\u001b[0m[0009] Starting helpers...                          \n",
      "\u001b[36mINFO\u001b[0m[0009] Starting Node 'k3d-zenml-kubeflow-registry.localhost' \n",
      "\u001b[36mINFO\u001b[0m[0009] Starting Node 'k3d-zenml-kubeflow-edfcfa45-serverlb' \n",
      "\u001b[36mINFO\u001b[0m[0017] Injecting '172.25.0.1 host.k3d.internal' into /etc/hosts of all nodes... \n",
      "\u001b[36mINFO\u001b[0m[0017] Injecting records for host.k3d.internal and for 3 network members into CoreDNS configmap... \n",
      "\u001b[36mINFO\u001b[0m[0020] Cluster 'zenml-kubeflow-edfcfa45' created successfully! \n",
      "\u001b[36mINFO\u001b[0m[0021] You can now use it like this:                \n",
      "kubectl cluster-info\n",
      "\u001b[1;35mFinished K3D cluster creation.\u001b[0m\n",
      "\u001b[1;35mDeploying Kubeflow Pipelines.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!zenml stack up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "296a2143",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!zenml stack set local_kubeflow_stack\n",
    "# Lets train within kubeflow pipelines\n",
    "!python run_pipeline.py train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf530aa6",
   "metadata": {},
   "source": [
    "# Chapter 3 - The Prediction Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b3ee8ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's return to our local stack\n",
    "!zenml stack set local_stack"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec9d6e37",
   "metadata": {},
   "source": [
    "![Training And Inference Pipeline](_assets/Training%20and%20Inference%20Pipeline.png \"Planned Architecture Full\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31d3c085",
   "metadata": {},
   "outputs": [],
   "source": [
    "from zenml.pipelines import pipeline\n",
    "\n",
    "\n",
    "@pipeline(enable_cache=False)\n",
    "def inference_pipeline(\n",
    "        importer,\n",
    "        preprocessor,\n",
    "        extract_next_week,\n",
    "        model_picker,\n",
    "        predictor,\n",
    "        post_processor\n",
    "):\n",
    "    \"\"\"Links all the steps together in a pipeline\"\"\"\n",
    "    season_schedule = importer()\n",
    "    processed_season_schedule = preprocessor(season_schedule)\n",
    "    upcoming_week = extract_next_week(processed_season_schedule)\n",
    "    model, run_id = model_picker()\n",
    "    predictions = predictor(model, upcoming_week)\n",
    "    readable_predictions = post_processor(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9d33ef2",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from steps.encoder import encode_columns_and_clean\n",
    "from steps.importer import import_season_schedule, SeasonScheduleConfig\n",
    "from steps.model_picker import model_picker\n",
    "from steps.predictor import predictor\n",
    "from steps.splitter import get_coming_week_data, TimeWindowConfig\n",
    "from steps.post_processor import data_post_processor\n",
    "\n",
    "# Initialize the pipeline\n",
    "inference_pipe = inference_pipeline(\n",
    "    importer=import_season_schedule(\n",
    "        SeasonScheduleConfig(current_season='2021-22')),\n",
    "    preprocessor=encode_columns_and_clean(),\n",
    "    extract_next_week=get_coming_week_data(TimeWindowConfig(time_window=7)),\n",
    "    model_picker=model_picker(),\n",
    "    predictor=predictor(),\n",
    "    post_processor=data_post_processor()\n",
    ")\n",
    "\n",
    "inference_pipe.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5b423e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets have a look at some of our predictions\n",
    "from zenml.repository import Repository\n",
    "\n",
    "r = Repository()\n",
    "df = r.get_pipeline(pipeline_name='inference_pipeline').runs[-1].steps[-1].output.read()\n",
    "df.head(20)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
